## 一、Kafka 

#### 1. kafka 的优势与应用场景

##### 优势：

> **高吞吐量、低延迟：**kafka 每秒可以处理几十万条消息，它的延迟最低只有几毫秒；
>
> **可扩展性：**kafka 集群支持热扩展；
>
> **持久性、可靠性：**消息被持久化到本地磁盘，并且支持数据备份防止数据丢失；
>
> **容错性：**允许集群中节点故障（若副本数量为n,则允许n-1个节点故障）；
>
> **高并发：**支持数千个客户端同时读写。

##### 应用场景：

> **日志收集：**一个公司可以用 Kafka 可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种 consumer；
>
> **消息系统：**解耦生产者和消费者、缓存消息等；
>
> **用户活动跟踪：**kafka 经常被用来记录 web 用户或者 app 用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到 kafka 的 topic 中，然后消费者通过订阅这些 topic 来做实时的监控分析，亦可保存到数据库；
>
> **运营指标：**kafka 也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；
>
> **流式处理：**比如 spark streaming 和 storm。

#### 2. 说明

Kafka 是一个分布式流式处理平台。

> 流平台具有三个关键功能：
>
> - 消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
> - 容错的持久⽅式存储记录消息流： Kafka 会把消息持久化到磁盘，有效避免了消息丢失的⻛险。
> - 流式处理平台： 在消息发布的时候进⾏处理， Kafka 提供了⼀个完整的流式处理类库。

> **概念：**
>
> - Producer（⽣产者）：产⽣消息的⼀⽅。
> - Consumer（消费者）：消费消息的⼀⽅。
> - Broker（代理）：可以看作是⼀个独⽴的 Kafka 实例。多个 Kafka Broker 组成⼀个 KafkaCluster  
>
> 每个 Broker 中⼜包含了 Topic 以及 Partition  
>
> - Topic（主题）：Producer 将消息发送到特定的主题， Consumer 通过订阅特定的 Topic（主题）来消费消息。
> - Partition（分区）：Partition 属于 Topic 的⼀部分。⼀个 Topic 可以有多个 Partition，并且同⼀ Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明⼀个 Topic 可以横跨多个 Broker  
>
>   （1）Partition 的数据文件又包含了 offset，MessageSize，data
>
>   - offset：Message 在这个 partition 中的偏移量，并不是该 Message 在 Partition 中的实际存储位置，而是一个逻辑值，可以理解为是 Partition 中 Msg 的 ID，
>   - MessageSize：消息内容 data 的大小
>   - data：具体的消息内容
>
>   （2）Replica 副本
>
>   - 每个分区可以有多个副本。
>   - 多个副本中有一个 leader 和多个 follower。
>   - 每个副本被分布在不同的 Broker 上。
>   - 当 leader 挂掉后，会从副本中选择一个新的 leader 继续服务。

> 应用场景：
>
> **异步：**
>
> **削峰：**
>
> **解耦：**

> **为什么那么快：**
>
> - 利用 Partition 实现并行处理
>
>   1. Partition 可位于不同的机器，可充分利用集群优势，实现机器间的并行处理。
>   2. Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可以通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘上的并行处理，充分发挥多磁盘的优势。
>
> - 顺序写 
>
>   1. Kafka 中每个分区是一个**有序的**，**不可变**的消息序列。新的消息不断地追加到 partition 的末尾。
>   2. 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。
>
> - PageCache 缓存
>
>   ​	1. 提高了 Linux 操作系统对磁盘访问的性能。Cache 在内存中缓存了磁盘上的部分数据。
>
> - Zero-copy 零拷技术减少拷贝次数。
>
>   只用将磁盘文件的数据复制到页面缓存中一次，然后将数据从页面缓存直接发送到网络中（发送给不同的订阅者时，都可以使用同一个页面缓存），避免了重复复制操作。
>
>   1. 传统的读取文件数据并发送到网络的步骤：
>
>   ​	（1）操作系统将数据从磁盘文件中读取到内核空间的页面缓存；
>   ​    （2）应用程序将数据从内核空间读入用户空间缓冲区；
>   ​    （3）应用程序将读到数据写回内核空间并放入socket缓冲区；
>   ​    （4）操作系统将数据从socket缓冲区复制到网卡接口，此时数据才能通过网络发送。
>
> - Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。
>
>   1. Kafka 的客户端和 broker 会在通过网络发送数据之前，在一个批处理中累计多条记录（包括读/写），记录的批处理分摊了网络往返的开销。
>
> - Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。
>
> - 数据压缩
>
>   1. Producer 可将数据压缩后发送给 broker，从而减少网络传输的代价。



#### 3. 消息模型

**发布/订阅模型（Pub/Sub）：**

使用 **主题（Topic）**作为消息通讯载体，类似于广播模式。

生产者发布一条消息，该消息通过主题传递给所有消费者，**在一条消息广播之后才订阅的用户是收不到该条消息的**。

在发布/订阅模型中，如果只有⼀个订阅者，那它和队列模型就基本是⼀样的了。所以说，发布/订阅模型在功能层⾯上是可以兼容队列模型的。  

#### 4. Kafka 多副本机制

Kafka 为分区（Partition）引入了多副本（Replica）机制。分区中的多个副本之间会有一个 lader，其他副本被称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

> 生产者和消费者只与 leader 副本进行交互，可以理解为其他副本只是 leader 副本的拷贝，他们的存在只是为了保证消息存储的安全性。当 leader  副本发生故障时，会从 follower 中选举出一个 leader，但是 follower 中如果有和 leader 同步程度达不到要求的，参加不了 leader 的选举。

**Kafka 多分区与多副本的好处：**

1. Kafka 通过给特定的 Topic 知道多个 Partition，而各个 Partition 可以分布在不同的 Broker 上，这样便能提供比较好的并发能力（负载均衡）。
2. Partition 可以指定对应的 Replica 数，也极大的提高了消息存储的安全性，提高了容灾能力，不过也相应的增加了所需要的存储空间。  

#### 5. Zookeeper 在 Kafka中的作用

> **Broker 注册：**
>
> Zookeeper 上会有一个专门用来**进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper上进行注册，即到 brokers/ids 下创建属于自己的节点。每个 Broker 会将自己的 IP 和 Port 等信息记录到该节点中去。 
>
> **Topic 注册：**
>
> 在 Kafka 上 同一个 Topic 的消息会被分到不同的片区，并将其分布在多个 Broker 上，这些**分区信息与 Broker 的对应关系**也是由 Broker 在维护。
>
> 比如，创建一个名为 my-topic 的主题并且它有两个分区，对应到 Zookeeper 中会创建这些文件夹：
>
> /brokers/topics/my-topic/Partitions/0、/brokers/topics/my-topic/Partitions/1
>
> **负载均衡：**
>
> Kafka 通过给特定 Topic 指定多个 Partition，而各个 Partition 可以分布在不同的 Broker 上，这样便能提供比较好的并发能⼒。

#### 6. 顺序消费

因为，消息是保存到 Partition 中的，而且 Partition 又存在于 Topic，一个 Topic 可以指定多个 Partition。

每次消息添加到 Partition 时都会采用队尾追加，所以 **Partition 中的消息是有序的**。

所以，1. 可以为每个 Topic 都只创建一个 Partition；2. 发送消息时，指定一个 Partition

#### 7. 重复消费

1. kafka 自带的消费机制

   当每个消息写入 Partition 时都会有一个 offset，代表他的序号。然后 consummer 消费数据后，每隔一段时间，会把自己消费过的消息的 offset 提交一下，代表我已经消费过了，下次要是重启，就回从上次消费到的 offset 来继续消费。

   但是，当我们直接 kill 进程，在重启。就会导致 consummer 有些消息处理了，但是没来得及提交 offset，等重启之后，少数消息就会被重复消费。

2. 通过保证消息的幂等性来保证

   **幂等性：**一条数据无论被请求多少次，对应的数据都不会改变。

   1. 生产者发送每条数据时，里边加一个全局唯一 ID，consumer 端先根据 ID 去 Redis 里查一下，没有则消费；有则忽略。
   2. 如果 consummer 消费数据是写库的话，先根据主键查一下，如果这数据都有了，就 update 一下。

#### 8. 消息丢失

1. 生产者丢失消息

   生产者调用 send() 方法发送消息之后，消息可能因为网络原因并没有发送过去。

   1. 可以通过 get() 方法获取调用结果。但 send() 是异步操作，调用 get() 方法后会使其变为同步操作。

   2. 添加其回调函数

      ```java
      ListenableFuture<SendResult<String, Objectjk future = kafkaTemplate.send(topic, o);
      future.addCallback(
      	result > logger.info("⽣产者成功发送消息到topic:{} partition:{}的消息", 
                   	result.getRecordMetadata().topic(), result.getRecordMetadata().partition()), 
      	ex > logger.error("⽣产者发送消失败，原因： {}", ex.getMessage()));
      ```

      **推荐为 Producer 的 retries（重试次数）设置一个合理值，一般为 3，但是为了保证消息不丢失的话会设置的比较大一点。**

      **另外，还要设置重试间隔，间隔太小的话效果不明显**

2. 消费者丢失消息

   当消费者拉取到 Partition 内的消息后，消费者会自动提交 offset。⾃动提交的话会有⼀个问题，当消费者刚拿到这个消息准备进⾏真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被⾃动提交了。

   解决办法也⽐较粗暴，我们⼿动关闭闭⾃动提交 offset，每次在真正消费完消息之后之后再⾃⼰⼿动提交 offset 。 但是，这样会带来消息被重新消费的问题。⽐如你刚刚消费完消息之后，还没提交 offset，结果⾃⼰挂掉了，那么这个消息理论上就会被消费两次。    

3. kafka 丢失消息

   Kafka 为 Partition 引入了多副本机制，多个副本中有一个 leader 和 多个 follwer。消息被发送到 leader 副本，然后 follower 从 leader 副本中拉取消息进行同步。

   **假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出⼀个 leader ，但是 leader 的数据还有⼀些没有被 follower 副本的同步的话，就会造成消息丢失。**  

   > **解决：**
   >
   >  <!-- 默认为即消息被 leader 副本接收后就算成功发送。设置为 all，表示所有副本都要接收到该消息后才算发送成功 -->
   >
   > acks = all
   >
   > <!-- 设置每个 partition 至少有 3 个副本 -->
   >
   > replication.factor ≥ 3  
   >
   > <!-- 设置消息至少要写入两个副本才算成功 -->
   >
   > min.insync.replicas > 1
   >
   > <!-- 当 leader 发生故障时，不会从和 leader 同步不达标的副本中选出 leader -->
   >
   > unclean.leader.election.enable = false

#### 9. 分布式事务



## 二、各 MQ 对比

> 1. ActiveMQ/ApolloMQ
>
> **优点：**老牌的消息队列，使用 Java 语言编写。对 JMS 支持最好，采用多线程并发，资源消耗比较大。如果你的主语言是 Java，可以重点考虑。
> **缺点：**由于历史悠久，历史包袱较多，版本更新很缓慢。集群模式需要依赖 Zookeeper 实现。最新架构的产品被命名为 Apollo，号称下一代 ActiveMQ，目前案例较少。
> 　　
>
> 2. RocketMQ/Kafka
>
> 　　**优点：**专为海量消息传递打造，主张使用拉模式，天然的集群、HA、负载均衡支持。话说还是那句话，适合不适合看你有没有那么大的量。
> 　　**缺点：**所谓鱼和熊掌不可兼得，放弃了一些消息中间件的灵活性，使用的场景较窄，需关注你的业务模式是否契合，否则山寨变相使用很别扭。除此之外，RocketMQ 没有 .NET 下的客户端可用。RocketMQ 身出名门，但使用者不多，生态较小，毕竟消息量能达到这种体量的公司不多，你也可以直接去购买阿里云的消息服务。Kafka 生态完善，其代码是用 Scala 语言写成，可靠性比 RocketMQ 低一些。
>
> 　　3. RabbitMQ
>
> **优点：**生态丰富，使用者众，有很多人在前面踩坑。AMQP 协议的领导实现，支持多种场景。淘宝的 MySQL 集群内部有使用它进行通讯，OpenStack 开源云平台的通信组件，最先在金融行业得到运用。
> 　　**缺点：**Erlang 代码你 Hold 得住不? 虽然 Erlang 是天然集群化的，但 RabbitMQ 在高可用方面做起来还不是特别得心应手，别相信广告。



**总结：**

- 如果消息队列不是将要构建系统的重点，对消息队列功能和性能没有很高的要求，只需要一个快速上手易于维护的消息队列，建议使用 RabbitMQ。
- 如果系统使用消息队列主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，需要低延迟和高稳定性，建议使用 RocketMQ。
- 如果需要处理海量的消息，像收集日志、监控信息或是埋点这类数据，或是你的应用场景大量使用了大数据、流计算相关的开源产品，那 Kafka 是最适合的消息队列。

