### 分布式

#### 讲一讲对分布式锁的了解

当开发的应用程序处于一个分布式的集群环境中，涉及到多节点，多进程共同完成时，想要保证线程的执行顺序是正确的，就需要一个全局锁实现多个线程(不同进程中的线程)之间的同步。

见的处理办法有三种：数据库、缓存、分布式协调系统

常用的分布式锁的实现包含：**Redis分布式锁**、**Zookeeper分布式锁**、**Memcached**

> 1. 基于数据库表做乐观锁，用于分布式锁。
> 2. 使用memcached的add()方法，用于分布式锁。
> 3. 使用memcached的cas()方法，用于分布式锁。(不常用)
> 4. 使用redis的setnx()、expire()方法，用于分布式锁。
> 5. 使用redis的setnx()、get()、getset()方法，用于分布式锁。
> 6. 使用redis的watch、multi、exec命令，用于分布式锁。(不常用)
> 7. 使用zookeeper，用于分布式锁。(不常用)

#### 分布式锁的实现、对比 redis 分布式锁 & zk **分布式锁**

> [Redis与Zookeeper实现分布式锁的区别](https://www.cnblogs.com/mengchunchen/p/9647756.html)
>
> **Redis 版本1**
>
> 1. 根据 lockKey 区进行 setnx（如果key值为空，则正常设置，返回1，否则不会进行设置并返回0），如果设置成功，则表示获得锁，否则表示没有获取锁
> 2. 如果没有获取锁，去 redis 上拿到该 key 对应的值，在该 key 上存储一个时间戳 t1，为了避免死锁以及其他客户端占用该锁超过一定时长（5s），使用该客户端当前时间戳，与存储的时间戳作比较。
> 3. 如果没有超过该 key 的使用时限，返回 false，表示其他人正在占用该 key，如果已经超过时限，那我们就可以进行解锁，使用我们的时间戳来代替该字段的值。
> 4. 但是如果在 setnx 失败后，get该值却无法拿到该字段时，说明操作之前该锁已经被释放，这个时候，最好的办法就是重新执行一遍setnx方法来获取其值以获得该锁。
> 5. 释放锁：删除 redis 中 key
>
> **Redis 版本2**
>
> 1. SET my:lock 随机值 NX PX 30000
>
> 　这个的 NX 的意思就是只有 key 不存在的时候才会设置成功，PX 30000 的意思是 30 秒后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。
>
> 　释放锁就是删除 key，但是一般可以用 lua 脚本删除，判断 value 一样才删除
>
>    为啥要用随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的lua脚本来释放锁。（就是根据这个随机值来判断这个锁是不是自己加的）
>
> **RedLock算法**
>
> 　这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁：
>
> 　获取当前时间戳，单位是毫秒
>
> 　轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒
>
> 　尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点（n / 2 +1）
>
> 　客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了
>
> 　要是锁建立失败了，那么就依次删除这个锁
>
> 　只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁
>
> **ZK 版本**
>
> 1. 客户端调用 create() 方法创建名为 “locknode/guid-lock-” 的节点，需要注意的是，这里节点的创建类型需要设置为 EPHEMERAL_SEQUENTIAL。
>
>  2. 客户端调用 getChildren(“locknode”) 方法来获取所有已经创建的子节点。
>
>  3. 客户端获取到所有子节点 path 之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，那么就认为这个客户端获得了锁。
>
>  4. 如果创建的节点不是所有节点中序号最小的，那么则监视比自己创建节点的序列号小的最大的节点，进入等待。直到下次监视的子节点变更的时候，再进行子节点的获取，判断是否获取锁。
>
>  5. 释放锁的过程相对比较简单，就是删除自己创建的那个子节点即可。临时节点是与会话绑定的，会话关闭后会自动删除

redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能

zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小

如果是 redis 获取锁的那个客户端 bug 了或者挂了，那么只能等待超时时间之后才能释放锁

而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁

#### 分布式事务中间件

JDTX（京东）

#### 分布式事务框架

##### **JTA：**

1. 两阶段提交
2. 事务时间太长,锁数据太长
3. 低性能,低吞吐量

##### **Seata：**

![](../img/分布式/seata.png)

Business 是业务入口，在程序中会通过**注解**来说明他是一个**全局事务**，这时他的角色为 TM（事务管理者）。

Business 会请求 TC（事务协调器，一个独立运行的服务），说明自己要开启一个全局事务，TC 会生成一个全局事务ID（XID），并返回给 Business。

Business 得到 XID 后，开始调用微服务，例如调用 Storage。

- Storage 会收到 XID，知道自己的事务属于这个全局事务。Storage 执行自己的业务逻辑，操作本地数据库。
- Storage 会把自己的事务注册到 TC，作为这个 XID 下面的一个**分支事务**，并且把自己的事务执行结果也告诉 TC。
- 此时 Storage 的角色是 RM（资源管理者），资源是指本地数据库。
- Order、Account 的执行逻辑与 Storage 一致。
- 在各个微服务都执行完成后，TC 可以知道 XID 下各个分支事务的执行结果，TM（Business） 也就知道了。
- Business 如果发现各个微服务的本地事务都执行成功了，就请求 TC 对这个 XID 提交，否则回滚。
- TC 收到请求后，向 XID 下的所有分支事务发起相应请求。
- 各个微服务收到 TC 的请求后，执行相应指令，并把执行结果上报 TC。

###### **重要机制**

（1）全局事务的回滚是如何实现的呢？

Seata 有一个重要的机制：**回滚日志**。

每个分支事务对应的数据库中都需要有一个回滚日志表 UNDO_LOG，在真正修改数据库记录之前，都会先记录修改前的记录值，以便之后回滚。

在收到回滚请求后，就会根据 UNDO_LOG 生成回滚操作的 SQL 语句来执行。

如果收到的是提交请求，就把 UNDO_LOG 中的相应记录删除掉。

（2）RM 是怎么自动和 TC 交互的？

是通过**监控拦截JDBC**实现的，例如监控到开启本地事务了，就会自动向 TC 注册、生成回滚日志、向 TC 汇报执行结果。

（3）二阶段回滚失败怎么办？

例如 TC 命令各个 RM 回滚的时候，有一个微服务挂掉了，那么所有正常的微服务也都不会执行回滚，当这个微服务重新正常运行后，TC 会重新执行全局回滚。







##### **EasyTransaction：**

#### 对XA、2PC、TCC的理解

**2PC：**

**TCC：**

#### 唯一id如何实现的，snowflake实现原理，snowflake有哪些问题，如何避免根据订单号可以推算出今天的订单量

。。。

#### feign 和 dubbo 有了解没有

。。。

#### eureka 和 zookeeper，了解多少说多少

。。。

#### hystrix 和 sentinel，了解多少说多少

。。。

#### Spring cloud alibaba，了解多少说多少

。。。

#### 一致性 hash

。。。

#### 服务A调用服务B，用户请求服务A，发现返回较慢，如何定位这个问题

**内存：**

**慢 SQL：**

#### [TIME_WAIT](https://blog.csdn.net/huangyimo/article/details/81505558)是什么状态还记得吗，什么情况下网络会出现这个状态

1. time_wait 状态如何产生？

对 TCP 连接中 time_wait 状态的理解：首先调用 closs() 发起主动关闭的一方，在发送最后一个 ACK 之后会进入 time_wait 状态。也就说该发送方会保持 2MSL 时间之后才会回到初始状态。MSL 值得是数据包在网络中的最大生存时间。产生这种结果使得这个 TCP 连接在 2MSL 连接等待期间，定义这个连接的四元组（客户端 IP 地址和端口，服务端 IP 地址和端口号）不能被使用。

2. time_wait 状态产生的原因

  3. time_wait 状态如何避免