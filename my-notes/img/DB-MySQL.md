## MySQL

#### 1. MySQL架构基础

1. 连接器

   连接器主要和身份认证和权限相关的功能相关。

   主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。

2. 查询缓存（MySQL 8.0 版本后移除）

   查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。

   MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。

3. 分析器

   **第一步，词法分析**，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。

   **第二步，语法分析**，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。

4. 优化器

   优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。

5. 执行器

   当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。

#### 2. 存储引擎

1. InnoDB

   行级锁、事务、外键、MVCC

   数据文件本身就是索引文件，B+Tree 叶子节点存放的是完整的数据记录。聚簇索引

   > **MVCC：**多版本并发控制
   >
   > ​	应对高并发事务，MVCC 比单纯的加锁更高效；
   >
   > ​	MVCC 仅在 READ-COMMITTED、EPEATABLE-READ 两个隔离级别下工作；
   >
   > ​	MVCC 可以用乐观锁和悲观锁实现

2. MyISAM

   表级锁、不支持事务、不支持外键

   索引文件和数据文件分离，B+Tree 叶子节点的 data 域存放的是数据记录的地址。非聚簇索引

#### 3. 索引

1. B+Tree

   必须要有且只有一个聚集索引。

   建议使用自增键、长整型为主键。

   队尾追加，减少碎片。

   优化范围查询，叶子节点，双指向

   > 聚簇索引：叶子节点存放的是完整的数据记录
   >
   > 普通索引：叶子节点存放的是主键记录
   >
   > **回表：**普通索引查询时无法直接定位行记录，通常情况下，需要扫描两遍索引树。
   >
   > (1) 先通过普通索引定位到主键值id；
   >
   > (2) 再通过聚集索引定位到行记录；
   >
   > **索引覆盖：**在一棵索引树上可以获取 SQL 所需的所有列数据时，则无需回表。
   >
   > 建立联合索引，将需要要查找的字段列加入联合索引

#### 4. [字符集及校对规则](https://www.cnblogs.com/geaozhang/p/6724393.html)



#### 5. 查询缓存



#### 6. 事务

事务是逻辑上的一组操作，要么都执行，要么都不执行。

##### 1. ACID

> **原子性：**事务是最⼩的执⾏单位，不允许分割。事务的原⼦性确保动作要么全部完成，要么完全不起作⽤
>
> **一致性：**执⾏事务前后，数据保持⼀致，多个事务对同⼀个数据读取的结果是相同的
>
> **隔离性：**并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间数据库是独⽴的
>
> **持久性：**⼀个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发⽣故障也不应该对其有任何影响

> **脏读：**
>
> **丢失修改：**
>
> **不可重复读：**
>
> **幻读：**

> **读未提交：**
>
> **读已提交：**
>
> **可重复读：**
>
> **串行化：**

##### 2. CAP

> **一致性：**
>
> **可用性：**
>
> **分区容错性：**

##### 3. 柔性事务

1. [二阶段提交](https://segmentfault.com/a/1190000012534071)

   将一个分布式事务过程拆分为两个阶段：**投票**和**事务提交**。

   **投票：**

   1. 协调者向所有参与者发送事务执行请求，并等待参与者返回事务执行结果；
   2. 事务参与者收到请求后，执行事务但不提交，并记录事务日志；
   3. 参与者将自己的事务执行情况反馈给协调者，同时阻塞等待协调者后续命令。

   **事务提交：**

    1. 所有参与者都回复能够正常执行事务，协调者向各个参与者发送 commit 通知，请求提交事务；
    2. 一个或多过参与者回复事务执行失败，协调者向各个参与者发送 rollback 通知，请求回滚事务；
    3. 协调者等待超时，协调者向各个参与者发送 rollback 通知，请求回滚事务。

   **缺点：**

   	1. 单点问题，一旦协调者宕机，那么参与者们将一直处于阻塞状态，整个数据库集群将无法提供服务。
    	2. 同步阻塞问题，所有参与者都要听从协调者统一调度，期间处于阻塞状态而不能进行其他操作，效率低下。
    	3. 数据不一致性，在协调者发出 commit 通知后，由于网络原因导致该通知一部分参与者收到并执行了 commit 操作，其余参与者因为没有收到通知而一直处于阻塞状态，这时就产生了数据不一致问题。

   **解决：**

   ​	**超时机制：**

   ​	**互询机制：**

   

2. [三阶段提交]()

   针对二阶段提交中的问题，三阶段提交引入了一个**预询盘**阶段，以及**超时策略**来减少整个集群的阻塞时间。

   三个阶段分别为：**预询盘**、**预提交**、**事务提交**

   **预询盘：**

   	1. 协调者向每个参与者发送事务询问通知，询问是否可以执行事务，并等待回复；
    	2. 各个参与者根据自身状态回复一个预估值，正常则回复确定信息，并进入预备状态，否则返回否定信息。

   **预提交：**

   	1. 所有参与者都返回确定信息，协调者向事务参与者发送**事务执行**通知；参与者收到通知单执行事务但不提交；参与者将执行结果返回协调者。
    	2. 一个或多过参与者回复否定信息，协调者向所有事务参数者发送 abort 通知；参与者收到通知后中断事务。
    	3. 协调者等待超时，协调者向所有事务参数者发送 abort 通知；参与者收到通知后中断事务。

   **事务提交：**

   	1. 所有参与者都能够正常执行事务，协调者向各个参与者发送 commit 通知；参与者执行 commit，并释放资源，反馈事务执行结果；
    	2. 一个或多过参与者回复事务执行失败，协调者向各个参与者发送 rollback 通知；参与者执行 rollback，并释放资源，反馈事务执行结果；
    	3. 协调者等待超时，协调者向各个参与者发送 rollback 通知；参与者执行 rollback，并释放资源，反馈事务执行结果；

   **缺点：**

   ​	如果进入 PreCommit 后，Coordinator 发出的是 abort 请求，假设只有一个 Cohort 收到并进行了 abort 操作，而其他对于系统状态未知的 Cohort 会根据 3PC 选择继续 Commit，此时系统状态发生不一致性。

   

3. [补偿型]()

   补偿提交是实现分布式最终一致性的一种思想，常见方案有 TCC，本地消息表，Sagas 模型等。

   > **TCC：** 共有两步：第一步是**尝试**，第二部是**确认/取消**。
   >
   > - 调用者向所有参与者发起尝试操作请求，并等待各个参与者的响应；
   > - 参与者接收到调用者的尝试操作请求后执行资源预留，例如要将张三的钱转 100 给李四，那么张三就执行冻结 100 的请求；
   > - 参与者执行操作成功，给协同者成功响应；反之，返回失败响应。例如张三冻结 100 成功返回成功响应，反之，返回失败；
   >
   > **本地消息表：**创建一张消息数据表，消息数据共有待发送、待确认、已发送三个状态。
   >
   > - 生产者执行业务操作，添加数据消息为待发送状态；后台定时检索待发送数据，发送给MQ并修改状态为待确认；收到消费者的 ACK 消息后，修改状态为已发送。
   >
   > - 消费者消费消息，处理业务；如果处理失败，可以基于本地消息表发起回滚消息到生产方，也可以人工修改。
   >
   > **Sagas：**
   >
   > - 拆分分布式系统中的长事务为多个子事务，最终拆分成多个节点的本地事务；
   > - 然后有序串行依次执行拆分后的子事务；
   > - 当所有子事务成功，那么长事务完成。否则，反向依次回滚已经完成的子事务。、

   

4. [异步确保型]()

   将一些同步阻塞的事务变为异步操作，避免对数据库事务的争用。

   典型例子：热点账户异步记账、批量记账的处理。

   

5. [最大努力通知型]()

   采用 MQ 的 ack 机制就可以实现最大努力通知（RocketMQ：每个消息必须消费并 ack 一次）
   
   典型例子：商户交易结果通知重试、补单重试	
   
   

##### 4. [事务日志](https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html)

> **redo log：**重做日志，提供前滚操作。
>
> 通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样。它用来恢复提交后的物理数据页（且只能回复到最后一次提交的位置）。
>
> redo log 的存在是为了：当我们修改的时候，写完了内存，但数据还没真正写入磁盘的时候，此时数据库挂了，那么可以根据redo log 进行数据恢复。**redo log 是顺序 IO，写入速度很快，记录的是物理变化（xx 页做了修改），恢复速度很快。**
>
> **undo log：**回滚日志，提供回滚操作。是 MVCC 的重要组成部分
>
> 一般是逻辑日志，根据每行记录进行记录。undo log 记录的是相反的操作，比如：我们要 insert 一条数据，那 undo log 会记录一条对应的 delete 操作。

> **innodb_flush_log_at_trx_commit=1/0/2**
>
> 默认 1，事务每次提交都会把 redo log buffer 写入磁盘；
>
> ​		0，不立即把 redo log buffer 写入磁盘，而是每秒刷新写入磁盘；
>
> ​		2，把 redo log buffer 写入 os buffer 缓存里去，然后每秒把 os buffer 写入磁盘。
>
> **sync_binlog=0/1/N**
>
> 默认 0，事务提交后，把 binlog 从缓冲写入磁盘，但不进行刷新操作，只是写入了操作系统缓存，若操作系统宕机则会丢失部分二进制日志。
>
> ​		1，事务提交后，将 binlog 写入磁盘并立即进行刷新操作，相当于徒步写入磁盘，不经过操作系统缓存。**如果启用了 binlog，则设置为 1**
>
> ​		N，每写 N 次，操作系统缓冲就执行一次刷新操作。

![mysql-log-buffer](img\mysql-log-buffer.png)

> redo log 写盘，InnoDB 事务进入准备阶段
>
> binlog 写盘，InnoDB 事务进入 commit 状态
>
> 每个事务 binlog 的末尾，会记录一个 XID event，标志着事务是否提交成功。



#### 7. 锁机制与 InnoDB 锁算法

InnoDB 的行锁是通过**锁住索引**来实现的，而不是记录。

1. **Record Lock：** 单个记录上的锁

2. **Gap Lock：** 间隙锁，锁定一个范围，但不包括记录本身

3. **Next-Key Lock：** Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身

   > (1) 在不通过索引查询时，InnoDB 会锁住表中的所有记录。
   >
   > (2) InnoDB 是通过索引来实现行锁的，而不是记录。因此，当操作的两条不同记录拥有相同的索引时，也会因为行锁被锁而发生等待。
   >
   > (3) 由于 InnoDB 的索引机制，数据库操作使用了主键索引，InnoDB 会锁住主键索引；使用非主键索引时，InnoDB 会先锁住非主键索引，再锁定主键索引。
   >
   > (4) 当查询索引是唯一索引时，InnoDB 会将 Next-Key Lock 降级为 Recode Lock，即只锁住索引本身，而不是范围。
   >
   > (5) InnoDB 对辅助索引有特殊处理，不仅会锁住索引值所在范围，还会将其下一键值加上 Gap Lock。 
   >
   > (6) InnoDB 采用 Next-Key Lock 机制来避免幻读问题。因为 Next-Key Lock 是锁住的一个范围，所以不会产生幻读问题。



#### 8. MVCC（多版本控制）

CAS 乐观锁

#### 9. SQL 优化

1. 一条 SQL 语句在 MySQL 中如何执行

   > **select：**先检查该语句是否有权限，查询缓存（8.0 以前），分析器，优化器，调用数据库引擎接口，返回引擎的执行结果。 
   >
   > **insert/update/delete：**
   >
   > - 先查询到这一条数据所在的页（MySQL的基本存储结构是页），然后把该页加载到内存中。如果有缓存，也是会用到缓存。
   > - 然后拿到查询的语句，修改列值，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log（记录日志前其实是先写 buffer），此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。
   > - 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。
   > - 更新完成。

2. 一条 SQL 执行很慢的原因

   > 偶尔很慢的情况：
   >
   > 1. 数据库在刷新脏页（flush）
   >
   >    当内存数据页跟磁盘数据页内容不一致时，这个内存页被称之为“脏页”，内存数据写入磁盘后，内存页和磁盘上的数据一致了，称为“干净页”。
   >
   >    flush 的 4 钟情景：redo log 写满了，内存不够用了，MySQL 认为系统空闲了，MySQL 正常关闭的时候
   >
   > 2. 拿不到锁
   >
   >    该语句涉及到的表或行正在被其他人使用，并且加锁了。
   >
   >    **show processlist; **显示哪些线程正在运行
   >
   >    **select * from information_schema.innodb_locks; **查询正在锁的事务
   >
   >    **select * from information_schema.innodb_lock_waits;** 查询等待锁的事务 
   >
   > 一直很慢的情况：
   >
   >  1. 没用索引
   >
   >       1. 字段没有索引
   >       2. 字段有索引，但却没有用索引（where 条件上的字段有运算或者函数）。
   >
   >  2. 数据库选错索引了
   >
   >     MySQL 在执行 SQL 时会进行**预测**，来判断究竟是走索引扫描的行数少，还是直接全表扫描的行数少。
   >
   >     **预测：** 
   >
   >     ​	系统通过**索引的区分度（基数）**来进行判断，一个索引上不同的值越多，意味着索引的区分度越高。
   >
   >     ​	系统通过**采样**的方式来预测索引的基数，所以就有可能出现失误的情况。
   >
   >     **强制走索引：**select * from t force index(idx) where c > 100 and c < 100000;
   >
   >     可以通过 **show index from t; **来检查索引的基数是否与实际相符；
   >
   >     可以通过 **analyze table t;**  来重新统计索引的基数。

3. SQL 规范

   1. 不要使用 **select * ，而是 select 具体的字段**。

      > 节省资源，减少网络开销
      >
      > select * 进行查询时，很可能就不会使用到覆盖索引了，就会造成回表查询

   2. 如果知道查询结果只有一条或者只要最大/最小的一条记录，建议用 **limit 1**。

      > 加上 limit 1 后，只要找到了对应的一条记录，就不会继续向下扫描了，效率将会大大提高。

   3. 尽量避免在 where 中使用 or 来连接条件

      > 在 同一列且带索引时，会使用索引；如 select * from t where id = 1 or id = 2; 
      >
      > 在 不同列且带索引时，会使用索引；如 select * from t where id = 1 or uuid = 2; 
      >
      > 在 不同列且有字段不带索引时，不会使用索引；如 select * from t where id = 1 or age = 2;

   4. 优化 limit 分页

      > 当偏移量越大时，查询效率就越低，因为 MySQL 并非是跳过偏移量直接去去后面的数据，而是先查询偏移量 + 要取的条数，然后再把前边偏移量这一段的数据抛弃掉再返回的。
      >
      > 反例：select * from t limit 10000, 10
      >
      > 正例：select * from t where id > 10000 limit 10; 或者 select * from t order by id limit 10000, 10; 

   5. 优化 like 语句

   6. 索引列上不要使用函数

   7. 索引列上不要进行表达式操作

   8. 关联查询尽量使用 Inner join，如果是 Left join ，左边表结果尽量小

   9. 避免在 where 子句中使用 != 或 <> 操作符

   10. 注意索引列的顺序，遵循最左匹配原则

   11. 在 where 及 order by 涉及的字段上建立索引

   12. 如果插入数据过多，考虑批量插入

   13. 使用覆盖索引，减少回表操作

   14. 慎用 distinct 关键字

       > 在查询一个或很少的字段时使用，可以带来优化效果，但在查询字段很多时，却会降低查询效率。
       >
       > 带 distinct 的语句占用系统资源和 CPU 时间都高于不带 distinct 的语句。因为当查询很多字段时，如果使用 distinct，数据库引擎就会对数据进行比较，过滤掉重复数据，然而这个比较，过滤的过程会占用系统资源，cpu 时间。

   15. 删除冗余和重复索引

   16. 如果数据量较大，优化修改/删除语句

       > 避免同时修改/删除过多数据，会造成 CPU 利用率过高
       >
       > 一次性删除太多数据，可能会有 lock wait timeout exceed 的错误，建议分批操作

   17. 设置默认值

   18. 不要有超过 5 个以上的表连接

   19. 合理利用 exists & in

       > MySQL 优化原则，小表驱动大表，小数据集驱动大数据集
       >
       > 子查询数据量小则使用 in，反之则使用 exists 
       >
       > exists 查询的理解就是，先执行主查询，获得数据后，再放到子查询中做条件验证，根据验证结果（true 或者 false），来决定主查询的数据结果是否得意保留

   20. 尽量用 union all 替换 union

       > 如果使用 union，不管检索结果有没有重复，都会尝试进行合并，然后在输出最终结果前进行排序

   21. 索引不宜太多，一般 5 个以内

   22. 尽量使用数字型字段，若只含数值信息，尽量不要设计为字符型

       > 相对于数字型字段，字符型会降低查询和连接的性能，并会增加存储开销。

   23. 索引不宜加在有大量重复数据的字段上

   24. 尽量避免向客户端返回过多数据量

   25. 当在 SQL 语句中连接多个表时,请使用表的别名，并把别名前缀于每一列上，这样语义更加清晰。

   26. 尽可能使用 varchar/nvarchar 代替 char/nchar。

       > 因为首先变长字段存储空间小，可以节省存储空间。
       >
       > 其次对于查询来说，在一个相对较小的字段内搜索，效率更高。

   27. 如果字段类型是字符串，where 时一定用引号括起来，否则索引失效

   28. 使用 explain 分析你 SQL 的计划

#### 10. Paxoc 算法



页 --> 16KB	

页目录 --> 2 分查找法 查找页目录



## 面试题：

#### 1. MyISAM 与 InnoDB 的区别

​    **MyISAM** 支持全文检索，压缩，空间函数，但不支持行级锁和事务，不支持外键，索引和数据是分开存储的。

​    **InnoDB** 是基于聚簇索引建立的，支持事务、行级锁和外键，索引和数据是存储在一起的。

#### 2. InnoDB 索引

B+ 树索引：

​		聚簇索引：是左小又大的顺序存储结构，节点只包含 id 索引列，叶子节点包含 id 和数据，如果没有定义主键，InnoDB 会选择一个唯一的非空索引代替。没有的话会隐式的定义一个主键。

​		非聚簇索引：叶子节点包含 主键 id

Hash 索引：



#### 3. 覆盖索引和回表

​		在一次查询中，如果一个索引包含或者说覆盖所有需要的查询的字段的值，就称之为覆盖索引，而不再需要回表查询。

#### 4. 锁的类型

**共享锁**和**排他锁**，即**读锁**和**写锁**

​		读锁是共享的，可以通过 lock in share mode 实现，这时候只能读不能写。

​		写锁是排他的，会阻塞其他的读锁和写锁。

**表级锁**和**行级锁**

​		表锁会锁定整张表，并且阻塞其他用户的读操作和写操作，比如 alter 修改表结构时。

​		行锁分为乐观锁和悲观锁，悲观通过 for update 实现，乐观锁通过版本号实现。

#### 5. 事务的基本特性和隔离级别

事务：

​		**原子性：**

​		**一致性**		

​		**隔离性：**

​		**持久性：**

隔离级别：

​		**读未提交：**

​		**读已提交：**

​		**可重复读：**

​		**串行化：**

#### 6. ACID 靠什么保证

原子性：由 undo log 日志保证，它记录了需要回滚的日志信息

一致性：由代码层来保证

隔离性：由 MVCC 来保证

持久性：由内存 + redo log 来保证

#### 7. 幻读和 MVCC

MVCC：多版本并发控制，是一种乐观锁。MySQL中每行数据实际隐藏了两列，创建时间版本号和删除时间版本号，每开始一个事务版本号都会自动递增。

幻读：专指新插入的行。A 开启事务，查询 id 为 5 的数据，发现不存在，B 开启事务，插入 id 为 5 的数据，B 提交事务，A 插入 id 为 5 的数据，唯一索引冲突。

解决办法：间隙锁

#### 8. 间隙锁



#### 9. 分库分表

水平分表：

垂直分表：

#### 10. 分表后的ID唯一性

 设置步长

 分布式ID，比如雪花算法

 分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一键使用，比如订单表订单号是唯一的。

 注：MySQL 不推荐使用 UUID 或 雪花算法作为主键 ID，因为 B+ 树是有序的，

#### 11. 分表后的非 sharding_key 的查询怎么处理

做一个 mapping 映射表

同步到离线（实时）数仓

多线程扫描表，然后再聚合结果

#### 12. MySQL 主从同步

master 提交完事务后，写入 binlog

 slave 连接到 master，获取 binlog

master 创建 dump 线程，推送 binlog 到 slave

 slave 开启一个 IO 线程读取同步过来的 binlog，记录到 relay log 中继日志 中

 salve 再开启以一个 SQL 线程读取 relay log 并在 slave 执行，完成同步

 slave 记录自己的 binlog

 全同步日志：所有 slave 都执行完成

 半同步机制：从库写入日志成功后返回 ACK 确认给 master，master 收到至少一个 slave 的 ACK 就认为同步完成 

#### 13. 去重

distinct：将所有 col 列中的内容都存入内存中，可以理解为 hash 结构，内存消耗大。

group by：先将 col 排序

####  14. LSM 树



#### 15. undolog 和 redolog 大小限制

> **undolog：**
>
> - **innodb_max_undo_log_size：**默认大小为 1G
>
> **redolog：**
>
> - **innodb_log_file_size：**默认大小为 48M

#### 16. 读写分离

**主从复制原理：**主库将变更写入 binlog 日志，然后从库连接主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志中读取 binlog，然后执行 binlog 日志中的内容，保证自己跟从库的日志是一样的。

从库同步主库数据的过程是串行化的。也就是说主库上的并行操作，在从库上会串行执行。

**半同步复制：**解决主库数据丢失问题。指主库写入 binlog 日志后，强制此时立即同步到从库，从库将日志写入 relay log 后，会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 后才会认为写操作完成。

**并行复制：**解决主从同步延时问题。从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志。这是**库级别**的并行。

#### 17.慢 SQL 查询分析

 1. 会产生 慢 的情况：索引、数据量大

    数据量大：使用 limit；通过 where 优化 limit；分库分表

    索引：where 上是否使用函数；最左前缀匹配；索引长度；回表；

    **排查：**

    ​	**explain：**

     1. 字段解释

        > **id：**选择标识符
        > **select_type：**表示查询的类型
        >
        > ​	(1) SIMPLE(简单SELECT，不使用UNION或子查询等)
        >
        > ​	(2) PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY)
        >
        > ​	(3) UNION(UNION中的第二个或后面的SELECT语句)
        >
        > ​	。。。。。。
        >
        > **table：**输出结果集的表
        > **type：**表示表的连接类型
        >
        > ​	(1) ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行
        >
        > ​	(2) index：Full Index Scan，index与ALL区别为index类型只遍历索引树
        >
        > ​	(3) range：只检索给定范围的行，使用一个索引来选择行
        >
        > ​	(4) ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值
        >
        > ​	(5) eq_ref：类似 ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用 primary key 或者 unique key 作为关联条件
        >
        > ​	(6) const、system：当 MySQL 对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于 where 列表中，MySQL 就能将该查询转换为一个常量，system 是 const 类型的特例，当查询的表只有一行的情况下，使用 system
        >
        > ​	(7) NULL：MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。
        >
        > **possible_keys：**表示查询时，可能使用的索引
        > **key：**表示实际使用的索引
        > **key_len：**索引字段的长度
        > **ref：**列与索引的比较
        > **rows：**扫描出的行数(估算的行数)
        > **Extra：**执行情况的描述和说明

    

    ​	**show profile：**会在后台保存最近15次的运行结果。

       			1. 通过 Show Profile 能查看 SQL 的耗时

    ![](img/mysql_show_profiles.png)

       2. 通过 Query_ID 可以得到具体 SQL 从连接 - 服务 - 引擎 - 存储四层结构完整生命周期的耗时

          ![](img/mysql_show_profiles_2.png)

          > **# 可用参数 type：**
          >
          > ALL  　　          # 显示所有的开销信息
          > BLOCK IO　　 # 显示块IO相关开销
          > CONTEXT SWITCHES　　#上下文切换相关开销
          > CPU                  # 显示CPU相关开销信息
          > IPC                    # 显示发送和接收相关开销信息
          > MEMORY　     # 显示内存相关开销信息
          > PAGE FAULTS　　# 显示页面错误相关开销信息
          > SOURCE　　   # 显示和Source_function，Source_file，Source_line相关的开销信息
          > SWAPS　　     # 显示交换次数相关开销的信息

       3. 出现这四个 status 时说明有问题，group by 可能会创建临时表

          > **# 危险状态：**
          >
          > converting HEAP to MyISAM  　　# 查询结果太大，内存不够用了，在往磁盘上搬
          > Creating tmp table         　　          # 创建了临时表，回先把数据拷贝到临时表，用完后再删除临时表
          > Copying to tmp table on disk 　    # 把内存中临时表复制到磁盘，危险！！！
          > locked