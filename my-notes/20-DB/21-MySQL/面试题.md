#### 1. MyISAM 与 InnoDB 的区别

​    **MyISAM** 支持全文检索，压缩，空间函数，但不支持行级锁和事务，不支持外键，索引和数据是分开存储的。

​    **InnoDB** 是基于聚簇索引建立的，支持事务、行级锁和外键，索引和数据是存储在一起的。

#### 2. InnoDB 索引

B+ 树索引：

​		聚簇索引：是左小又大的顺序存储结构，节点只包含 id 索引列，叶子节点包含 id 和数据，如果没有定义主键，InnoDB 会选择一个唯一的非空索引代替。没有的话会隐式的定义一个主键。

​		非聚簇索引：叶子节点包含 主键 id

Hash 索引：



#### 3. 覆盖索引和回表

​		在一次查询中，如果一个索引包含或者说覆盖所有需要的查询的字段的值，就称之为覆盖索引，而不再需要回表查询。

#### 4. 锁的类型

**共享锁**和**排他锁**，即**读锁**和**写锁**

​		读锁是共享的，可以通过 lock in share mode 实现，这时候只能读不能写。

​		写锁是排他的，会阻塞其他的读锁和写锁。

**表级锁**和**行级锁**

​		表锁会锁定整张表，并且阻塞其他用户的读操作和写操作，比如 alter 修改表结构时。

​		行锁分为乐观锁和悲观锁，悲观通过 for update 实现，乐观锁通过版本号实现。

#### 5. 事务的基本特性和隔离级别

事务 ACID：

​		**原子性：**

​		**一致性**		

​		**隔离性：**

​		**持久性：**

隔离级别：

​		**读未提交：**脏读、不可重复读、幻读

​		**读已提交：**不可重复读、幻读

​		**可重复读：**幻读

​		**串行化：**

> **脏读：**
>
> ​	事务 A 读取到事务 B 还未提交的事务
>
> **不可重复读：**
>
> ​	在一个事务中读取了两次某数据，读取出的数据不一致，**针对数据更新操作**
>
> **幻读：**
>
> ​	在一个事务中发现了未被操作的事务，**针对数据插入操作**

#### 6. ACID 靠什么保证

原子性（atomicity）：由 undo log 日志保证，它记录了需要回滚的日志信息

一致性（consistency）：由代码层来保证

隔离性（isolation）：由 MVCC 来保证

持久性（durability）：由内存 + redo log 来保证

#### 7. 幻读和 MVCC

MVCC：多版本并发控制，是一种乐观锁。MySQL中每行数据实际隐藏了两列，创建时间版本号和删除时间版本号，每开始一个事务版本号都会自动递增。

幻读：专指新插入的行。A 开启事务，查询 id 为 5 的数据，发现不存在，B 开启事务，插入 id 为 5 的数据，B 提交事务，A 插入 id 为 5 的数据，唯一索引冲突。

解决办法：间隙锁

#### 8. 间隙锁



#### 9. 分库分表

水平分表：

垂直分表：

#### 10. 分表后的ID唯一性

 设置步长

 分布式ID，比如雪花算法

 分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一键使用，比如订单表订单号是唯一的。

 注：MySQL 不推荐使用 UUID 或 雪花算法作为主键 ID，因为 B+ 树是有序的，

#### 11. 分表后的非 sharding_key 的查询怎么处理

做一个 mapping 映射表

同步到离线（实时）数仓

多线程扫描表，然后再聚合结果

#### 12. MySQL 主从同步

master 提交完事务后，写入 binlog

 slave 连接到 master，获取 binlog

master 创建 dump 线程，推送 binlog 到 slave

 slave 开启一个 IO 线程读取同步过来的 binlog，记录到 relay log 中继日志 中

 salve 再开启以一个 SQL 线程读取 relay log 并在 slave 执行，完成同步

 slave 记录自己的 binlog

 全同步日志：所有 slave 都执行完成

 半同步机制：从库写入日志成功后返回 ACK 确认给 master，master 收到至少一个 slave 的 ACK 就认为同步完成 

#### 13. 去重

distinct：将所有 col 列中的内容都存入内存中，可以理解为 hash 结构，内存消耗大。

group by：先将 col 排序

####  14. LSM 树



#### 15. undolog 和 redolog 大小限制

> **undolog：**
>
> - **innodb_max_undo_log_size：**默认大小为 1G
>
> **redolog：**
>
> - **innodb_log_file_size：**默认大小为 48M

#### 16. 读写分离

**主从复制原理：**主库将变更写入 binlog 日志，然后从库连接主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志中读取 binlog，然后执行 binlog 日志中的内容，保证自己跟从库的日志是一样的。

从库同步主库数据的过程是串行化的。也就是说主库上的并行操作，在从库上会串行执行。

**半同步复制：**解决主库数据丢失问题。指主库写入 binlog 日志后，强制此时立即同步到从库，从库将日志写入 relay log 后，会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 后才会认为写操作完成。

**并行复制：**解决主从同步延时问题。从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志。这是**库级别**的并行。

#### 17. 慢 SQL 查询分析

会产生 慢 的情况：索引、数据量大

数据量大：使用 limit；通过 where 优化 limit；分库分表

索引：where 上是否使用函数；最左前缀匹配；索引长度；回表；

**排查：**

​	**explain：**

 1. 字段解释

    > **id：**选择标识符
    > **select_type：**表示查询的类型
    >
    > ​	(1) SIMPLE(简单SELECT，不使用UNION或子查询等)
    >
    > ​	(2) PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY)
    >
    > ​	(3) UNION(UNION中的第二个或后面的SELECT语句)
    >
    > ​	。。。。。。
    >
    > **table：**输出结果集的表
    > **type：**表示表的连接类型
    >
    > ​	(1) ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行
    >
    > ​	(2) index：Full Index Scan，index与ALL区别为index类型只遍历索引树
    >
    > ​	(3) range：只检索给定范围的行，使用一个索引来选择行
    >
    > ​	(4) ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值
    >
    > ​	(5) eq_ref：类似 ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用 primary key 或者 unique key 作为关联条件
    >
    > ​	(6) const、system：当 MySQL 对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于 where 列表中，MySQL 就能将该查询转换为一个常量，system 是 const 类型的特例，当查询的表只有一行的情况下，使用 system
    >
    > ​	(7) NULL：MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。
    >
    > **possible_keys：**表示查询时，可能使用的索引
    > **key：**表示实际使用的索引
    > **key_len：**索引字段的长度
    > **ref：**列与索引的比较
    > **rows：**扫描出的行数(估算的行数)
    > **Extra：**执行情况的描述和说明

​	**show profile：**会在后台保存最近15次的运行结果。

1. 通过 Show Profile 能查看 SQL 的耗时

![](../img/mysql_show_profiles.png)

   2. 通过 Query_ID 可以得到具体 SQL 从连接 - 服务 - 引擎 - 存储四层结构完整生命周期的耗时

      ![](../img/mysql_show_profiles_2.png)

      > **# 可用参数 type：**
      >
      > ALL  　　          # 显示所有的开销信息
      > BLOCK IO　　 # 显示块IO相关开销
      > CONTEXT SWITCHES　　#上下文切换相关开销
      > CPU                  # 显示CPU相关开销信息
      > IPC                    # 显示发送和接收相关开销信息
      > MEMORY　     # 显示内存相关开销信息
      > PAGE FAULTS　　# 显示页面错误相关开销信息
      > SOURCE　　   # 显示和Source_function，Source_file，Source_line相关的开销信息
      > SWAPS　　     # 显示交换次数相关开销的信息

   3. 出现这四个 status 时说明有问题，group by 可能会创建临时表

      > **# 危险状态：**
      >
      > converting HEAP to MyISAM  　　# 查询结果太大，内存不够用了，在往磁盘上搬
      > Creating tmp table         　　          # 创建了临时表，回先把数据拷贝到临时表，用完后再删除临时表
      > Copying to tmp table on disk 　    # 把内存中临时表复制到磁盘，危险！！！
      > locked



#### 18. Mysql 区间分组查询

**使用 case when 或者 if 实现**

> select 
> 	count(if(id between 0 and 5, id , null ) ) as "0-5",
> 	count(if(id between 6 and 10, id , null ) ) as "6-10",
> 	count(if(id between 11 and 20, id , null ) ) as "11-20",
> 	count(if(id between 21 and 50, id , null ) ) as "21-50"
> from t_user ;

**使用 mysql 提供的 interval 函数 及 elt 函数**

interval(N,N1,N2,N3) ,比较列表中的 N 值，该函数如果 N<N1 返回 0，如果 N<N2 返回 1，如果 N<N3 返回 2 等等。

elt(n,str1,str2,str3,…) 如果 n=1，则返回 str1,如果 n=2，则返回 str2，依次类推

> select 
> 	elt(interval(id,0,6,11,21),"0-5","6-10","11-20","21-50") as region ,count(*) 
> from t_user group by region;

新建一个 temp 中间表，存储区间的上下限临界值，然后通过 join 关联查询

> select region,count(*)
> from t_user 
> left join tmp 
> on t_user.id between tmp.lower and tmp.upper
> group by region



#### 19. Mysql 语句执行顺序

| 关键字或 解释           | 执行顺序 |
| ----------------------- | -------- |
| select 查询列表（字段） | 第七步   |
| from 表                 | 第一步   |
| 连接类型 join 表2       | 第二步   |
| on 连接条件             | 第三步   |
| where 筛选条件          | 第四步   |
| group by 分组列表       | 第五步   |
| having 分组后的筛选条件 | 第六步   |
| order by 排序列表       | 第八步   |
| limit 偏移 ，条目数     | 第九步   |

